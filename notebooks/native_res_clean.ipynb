{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jluesch/micromamba/envs/dinov2/lib/python3.9/site-packages/torchvision/datapoints/__init__.py:12: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "/home/jluesch/micromamba/envs/dinov2/lib/python3.9/site-packages/torchvision/transforms/v2/__init__.py:54: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "/home/jluesch/Documents/GitHub/plankton-dinov2/notebooks/../dinov2/layers/attention.py:29: UserWarning: xFormers is available (Attention)\n",
      "  warnings.warn(\"xFormers is available (Attention)\")\n",
      "/home/jluesch/Documents/GitHub/plankton-dinov2/notebooks/../dinov2/layers/block.py:34: UserWarning: xFormers is available (Block)\n",
      "  warnings.warn(\"xFormers is available (Block)\")\n",
      "/home/jluesch/Documents/GitHub/plankton-dinov2/notebooks/../dinov2/layers/swiglu_ffn.py:43: UserWarning: xFormers is available (SwiGLU)\n",
      "  warnings.warn(\"xFormers is available (SwiGLU)\")\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.insert(0, \"..\")\n",
    "\n",
    "from dinov2.data.loaders import make_dataset\n",
    "import matplotlib.pyplot as plt\n",
    "from dinov2.data import DataAugmentationDINO\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from dinov2.data.masking import MaskingGenerator\n",
    "from dinov2.data.collate import collate_data_and_cast\n",
    "from dinov2.data import make_data_loader\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "from dinov2.models.vision_transformer import DinoVisionTransformer\n",
    "\n",
    "from dinov2.layers import (\n",
    "    MemEffAttention,\n",
    "    Mlp,\n",
    "    PatchEmbed,\n",
    "    SwiGLUFFNFused,\n",
    ")\n",
    "from dinov2.layers import (\n",
    "    NestedTensorBlock as Block,\n",
    ")\n",
    "\n",
    "\n",
    "root = \"/home/jluesch/Documents/data/plankton/nat_lmdb/\"\n",
    "ds_path = f\"LMDBDataset:split=TRAIN:root={root}:extra=*\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset kwargs {'split': <_Split.TRAIN: 'train'>, 'root': '/home/jluesch/Documents/data/plankton/nat_lmdb/', 'extra': '*'}\n",
      "extra_path /home/jluesch/Documents/data/plankton/nat_lmdb/*-TRAIN_*\n",
      "Datasets labels file list:  ['/home/jluesch/Documents/data/plankton/nat_lmdb/2007-TRAIN_labels', '/home/jluesch/Documents/data/plankton/nat_lmdb/2008-TRAIN_labels', '/home/jluesch/Documents/data/plankton/nat_lmdb/2009-TRAIN_labels', '/home/jluesch/Documents/data/plankton/nat_lmdb/2010-TRAIN_labels', '/home/jluesch/Documents/data/plankton/nat_lmdb/2011-TRAIN_labels', '/home/jluesch/Documents/data/plankton/nat_lmdb/2012-TRAIN_labels', '/home/jluesch/Documents/data/plankton/nat_lmdb/2013-TRAIN_labels', '/home/jluesch/Documents/data/plankton/nat_lmdb/2014-TRAIN_labels']\n",
      "Datasets imgs file list:  ['/home/jluesch/Documents/data/plankton/nat_lmdb/2007-TRAIN_imgs', '/home/jluesch/Documents/data/plankton/nat_lmdb/2008-TRAIN_imgs', '/home/jluesch/Documents/data/plankton/nat_lmdb/2009-TRAIN_imgs', '/home/jluesch/Documents/data/plankton/nat_lmdb/2010-TRAIN_imgs', '/home/jluesch/Documents/data/plankton/nat_lmdb/2011-TRAIN_imgs', '/home/jluesch/Documents/data/plankton/nat_lmdb/2012-TRAIN_imgs', '/home/jluesch/Documents/data/plankton/nat_lmdb/2013-TRAIN_imgs', '/home/jluesch/Documents/data/plankton/nat_lmdb/2014-TRAIN_imgs']\n",
      "lmdb_env_imgs.stat() {'psize': 4096, 'depth': 4, 'branch_pages': 904, 'leaf_pages': 119859, 'overflow_pages': 336375, 'entries': 289020}\n",
      "lmdb_env_imgs.stat() {'psize': 4096, 'depth': 3, 'branch_pages': 39, 'leaf_pages': 5028, 'overflow_pages': 503773, 'entries': 443660}\n",
      "lmdb_env_imgs.stat() {'psize': 4096, 'depth': 3, 'branch_pages': 65, 'leaf_pages': 8572, 'overflow_pages': 856950, 'entries': 752998}\n",
      "lmdb_env_imgs.stat() {'psize': 4096, 'depth': 3, 'branch_pages': 155, 'leaf_pages': 21332, 'overflow_pages': 363290, 'entries': 345381}\n",
      "lmdb_env_imgs.stat() {'psize': 4096, 'depth': 4, 'branch_pages': 419, 'leaf_pages': 54959, 'overflow_pages': 375588, 'entries': 439194}\n",
      "lmdb_env_imgs.stat() {'psize': 4096, 'depth': 4, 'branch_pages': 1043, 'leaf_pages': 135539, 'overflow_pages': 228467, 'entries': 401932}\n",
      "lmdb_env_imgs.stat() {'psize': 4096, 'depth': 4, 'branch_pages': 1326, 'leaf_pages': 174458, 'overflow_pages': 182436, 'entries': 421238}\n",
      "lmdb_env_imgs.stat() {'psize': 4096, 'depth': 4, 'branch_pages': 1025, 'leaf_pages': 134098, 'overflow_pages': 137438, 'entries': 329832}\n",
      "#unique_class_ids: _Split.TRAIN, 102\n"
     ]
    }
   ],
   "source": [
    "data_transform_cpu = DataAugmentationDINO(\n",
    "    [0.32, 0.8],\n",
    "    [0.05, 0.32],\n",
    "    local_crops_number=6,\n",
    "    global_crops_size=224,\n",
    "    local_crops_size=98,\n",
    "    use_kornia=True,\n",
    "    use_native_res=False,\n",
    "    do_seg_crops=False,\n",
    "    patch_size=14\n",
    ")\n",
    "\n",
    "dataset = make_dataset(\n",
    "    dataset_str=ds_path,\n",
    "    transform=data_transform_cpu,\n",
    "    target_transform=lambda x: (),\n",
    "    with_targets=True,\n",
    "    cache_dataset=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def list_collate(batch):\n",
    "    data = [item[0] for item in batch]\n",
    "    target = [item[1] for item in batch]\n",
    "    target = torch.LongTensor(target)\n",
    "    return [data, target]\n",
    "\n",
    "data_loader = make_data_loader(\n",
    "    dataset=dataset,\n",
    "    batch_size=16,\n",
    "    num_workers=8,\n",
    "    shuffle=True,\n",
    "    seed=0,\n",
    "    sampler_type=None,\n",
    "    sampler_advance=0,\n",
    "    drop_last=True,\n",
    "    collate_fn=None, #list_collate,\n",
    ")\n",
    "\n",
    "img_size = 224\n",
    "patch_size = 14\n",
    "mask_generator = MaskingGenerator(\n",
    "    input_size=(img_size // patch_size, img_size // patch_size),\n",
    "    max_num_patches=0.5 * img_size // patch_size * img_size // patch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DinoVisionTransformer(\n",
    "    patch_size=14,\n",
    "    embed_dim=384,\n",
    "    depth=12,\n",
    "    num_heads=6,\n",
    "    mlp_ratio=4,\n",
    "    block_fn=partial(Block, attn_class=MemEffAttention),\n",
    "    num_register_tokens=0,\n",
    "    img_size=224,\n",
    "    in_chans=3,\n",
    "    drop_path_rate=0.0,\n",
    "    drop_path_uniform=True,\n",
    "    init_values=1.0e-05,  # for layerscale: None or 0 => no layerscale\n",
    "    embed_layer=PatchEmbed,\n",
    "    ffn_layer=\"mlp\",\n",
    "    block_chunks=1,\n",
    "    interpolate_antialias=False,\n",
    "    interpolate_offset=0.1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 2, 3, 224, 224])\n",
      "torch.Size([16, 6, 3, 92, 92])\n",
      "collated_masks torch.Size([32, 256])\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Input image height 92 is not a multiple of patch height 14",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 23\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mamp\u001b[38;5;241m.\u001b[39mautocast():\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 23\u001b[0m         out \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m                \u001b[49m\u001b[43mcollated_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcollated_global_crops\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m                \u001b[49m\u001b[43mcollated_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcollated_local_crops\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m            \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmasks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mcollated_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcollated_masks\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m            \u001b[49m\u001b[43mis_training\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# attn_masks=[collated_dict[\"attn_mask_gc\"].cuda(),collated_dict[\"attn_mask_lc\"].cuda()]\u001b[39;49;00m\n\u001b[1;32m     31\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m         \u001b[38;5;28mprint\u001b[39m(out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx_norm_clstoken\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[0;32m~/micromamba/envs/dinov2/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Documents/GitHub/plankton-dinov2/notebooks/../dinov2/models/vision_transformer.py:414\u001b[0m, in \u001b[0;36mDinoVisionTransformer.forward\u001b[0;34m(self, is_training, *args, **kwargs)\u001b[0m\n\u001b[1;32m    413\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, is_training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 414\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_features\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    415\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_training:\n\u001b[1;32m    416\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "File \u001b[0;32m~/Documents/GitHub/plankton-dinov2/notebooks/../dinov2/models/vision_transformer.py:327\u001b[0m, in \u001b[0;36mDinoVisionTransformer.forward_features\u001b[0;34m(self, x, masks, attn_masks)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward_features\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, masks\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, attn_masks\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mlist\u001b[39m):\n\u001b[0;32m--> 327\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_features_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmasks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattn_masks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    329\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_tokens_with_masks(x, masks)\n\u001b[1;32m    331\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\" # Already done in collate\u001b[39;00m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;124;03m    if x.shape[1] < self.num_tokens:\u001b[39;00m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;124;03m        # Add padding tokens to reach fixed len\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;124;03m        x = self.pad_token_tensor_to_fixed_len(x)\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/GitHub/plankton-dinov2/notebooks/../dinov2/models/vision_transformer.py:270\u001b[0m, in \u001b[0;36mDinoVisionTransformer.forward_features_list\u001b[0;34m(self, x_list, masks_list, attn_mask_list)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward_features_list\u001b[39m(\u001b[38;5;28mself\u001b[39m, x_list, masks_list, attn_mask_list\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 270\u001b[0m     x \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    271\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_tokens_with_masks(x, masks)\n\u001b[1;32m    272\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m x, masks \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(x_list, masks_list)\n\u001b[1;32m    273\u001b[0m     ]\n\u001b[1;32m    274\u001b[0m     \u001b[38;5;66;03m# x_list = [global_crops, local_crops]\u001b[39;00m\n\u001b[1;32m    275\u001b[0m     \u001b[38;5;66;03m# masks_list = [masks, None]\u001b[39;00m\n\u001b[1;32m    276\u001b[0m     \u001b[38;5;66;03m# x[0] = B C H W\u001b[39;00m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;124;03m    x = [\u001b[39;00m\n\u001b[1;32m    279\u001b[0m \u001b[38;5;124;03m        self.pad_token_list_to_fixed_len(x, mask)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[38;5;124;03m    # Add padding tokens to reach fixed len\u001b[39;00m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/GitHub/plankton-dinov2/notebooks/../dinov2/models/vision_transformer.py:271\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward_features_list\u001b[39m(\u001b[38;5;28mself\u001b[39m, x_list, masks_list, attn_mask_list\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    270\u001b[0m     x \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m--> 271\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprepare_tokens_with_masks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    272\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m x, masks \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(x_list, masks_list)\n\u001b[1;32m    273\u001b[0m     ]\n\u001b[1;32m    274\u001b[0m     \u001b[38;5;66;03m# x_list = [global_crops, local_crops]\u001b[39;00m\n\u001b[1;32m    275\u001b[0m     \u001b[38;5;66;03m# masks_list = [masks, None]\u001b[39;00m\n\u001b[1;32m    276\u001b[0m     \u001b[38;5;66;03m# x[0] = B C H W\u001b[39;00m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;124;03m    x = [\u001b[39;00m\n\u001b[1;32m    279\u001b[0m \u001b[38;5;124;03m        self.pad_token_list_to_fixed_len(x, mask)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[38;5;124;03m    # Add padding tokens to reach fixed len\u001b[39;00m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/GitHub/plankton-dinov2/notebooks/../dinov2/models/vision_transformer.py:247\u001b[0m, in \u001b[0;36mDinoVisionTransformer.prepare_tokens_with_masks\u001b[0;34m(self, x, masks)\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprepare_tokens_with_masks\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, masks\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;66;03m# b c w h OR b c p (n p)\u001b[39;00m\n\u001b[1;32m    246\u001b[0m     B, nc, w, h \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m--> 247\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpatch_embed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# b n d (=384)\u001b[39;00m\n\u001b[1;32m    248\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m masks \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    249\u001b[0m         x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mwhere(\n\u001b[1;32m    250\u001b[0m             masks\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmask_token\u001b[38;5;241m.\u001b[39mto(x\u001b[38;5;241m.\u001b[39mdtype)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m), x\n\u001b[1;32m    251\u001b[0m         )\n",
      "File \u001b[0;32m~/micromamba/envs/dinov2/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Documents/GitHub/plankton-dinov2/notebooks/../dinov2/layers/patch_embed.py:74\u001b[0m, in \u001b[0;36mPatchEmbed.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     71\u001b[0m _, _, H, W \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m     72\u001b[0m patch_H, patch_W \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpatch_size\n\u001b[0;32m---> 74\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[1;32m     75\u001b[0m     H \u001b[38;5;241m%\u001b[39m patch_H \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     76\u001b[0m ), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput image height \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mH\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not a multiple of patch height \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpatch_H\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[1;32m     78\u001b[0m     W \u001b[38;5;241m%\u001b[39m patch_W \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     79\u001b[0m ), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput image width \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mW\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not a multiple of patch width: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpatch_W\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     80\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproj(x)  \u001b[38;5;66;03m# B C H W\u001b[39;00m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Input image height 92 is not a multiple of patch height 14"
     ]
    }
   ],
   "source": [
    "out = None\n",
    "torch.cuda.empty_cache()\n",
    "for i, el in enumerate(data_loader):\n",
    "    if i > 2:\n",
    "        break\n",
    "    el = el[0]\n",
    "    print(el[\"global_crops\"].shape)\n",
    "    print(el[\"local_crops\"].shape)\n",
    "    # list of len batch size containing dicts\n",
    "    collated_dict = collate_data_and_cast(\n",
    "        el,\n",
    "        mask_ratio_tuple=(0.1, 0.5),\n",
    "        mask_probability=0.5,\n",
    "        dtype=torch.half,\n",
    "        n_tokens=200,\n",
    "        mask_generator=mask_generator,\n",
    "        free_shapes=True,\n",
    "    )\n",
    "\n",
    "    model.cuda()\n",
    "    with torch.cuda.amp.autocast():\n",
    "        with torch.no_grad():\n",
    "            out = model(\n",
    "                [\n",
    "                    collated_dict[\"collated_global_crops\"].cuda(),\n",
    "                    collated_dict[\"collated_local_crops\"].cuda(),\n",
    "                ],\n",
    "                masks=[collated_dict[\"collated_masks\"].cuda(), None],\n",
    "                is_training=True,\n",
    "                # attn_masks=[collated_dict[\"attn_mask_gc\"].cuda(),collated_dict[\"attn_mask_lc\"].cuda()]\n",
    "            )\n",
    "            print(out[0][\"x_norm_clstoken\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_norm_clstoken torch.Size([32, 384])\n",
      "x_norm_regtokens torch.Size([32, 0, 384])\n",
      "x_norm_patchtokens torch.Size([32, 288, 384])\n",
      "x_prenorm torch.Size([32, 289, 384])\n",
      "masks torch.Size([32, 288])\n",
      "x_norm_clstoken torch.Size([16, 384])\n",
      "x_norm_regtokens torch.Size([16, 0, 384])\n",
      "x_norm_patchtokens torch.Size([16, 288, 384])\n",
      "x_prenorm torch.Size([16, 289, 384])\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(out)):\n",
    "    for k in out[i].keys():\n",
    "        if out[i][k] is not None:\n",
    "            print(k, out[i][k].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
